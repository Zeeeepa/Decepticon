---
description: AI 에이전트 개발과 멀티 에이전트 시스템 구축 규칙
globs: "src/agents/**/*.py"
alwaysApply: false
---

<rule>
<meta>
<title>AI Agent Development Standards</title>
<description>LangGraph 기반 AI 에이전트 개발과 멀티 에이전트 시스템 구축 표준</description>
<created-at utc-timestamp="1720684800">2025-07-08, 11:20 AM KST</created-at>
<last-updated-at utc-timestamp="1720684800">2025-07-08, 11:20 AM KST</last-updated-at>
<applies-to>
<file-matcher glob="src/agents/**/*.py">에이전트 구현 파일</file-matcher>
<file-matcher glob="src/graphs/**/*.py">에이전트 그래프 파일</file-matcher>
<file-matcher glob="src/prompts/**/*.py">프롬프트 관련 파일</file-matcher>
</applies-to>
</meta>

<requirements>
<requirement priority="critical">
<description>모든 에이전트는 표준화된 구조를 따르며, 메모리 도구와 핸드오프 도구를 포함한다.</description>
<examples>
<example title="표준 에이전트 구조">
<correct-example title="완전한 에이전트 구현" conditions="새로운 에이전트 생성" expected-result="표준화된 에이전트" correctness-criteria="메모리, MCP 도구, 핸드오프 도구 포함"><![CDATA[
from langgraph.prebuilt import create_react_agent
from langmem import create_manage_memory_tool, create_search_memory_tool
from src.prompts.prompt_loader import load_prompt
from src.tools.handoff import handoff_to_planner, handoff_to_summary
from src.utils.llm.config_manager import get_current_llm
from src.utils.memory import get_store
from src.utils.mcp.mcp_loader import load_mcp_tools

async def make_vulnerability_assessment_agent():
    """취약점 평가 에이전트 생성"""
    # LLM 로드 (기본값 fallback 포함)
    llm = get_current_llm()
    if llm is None:
        from langchain_anthropic import ChatAnthropic
        llm = ChatAnthropic(model="claude-3-5-sonnet-latest", temperature=0)
        print("Warning: Using default LLM model (Claude 3.5 Sonnet)")
    
    # 중앙 집중식 메모리 store 사용
    store = get_store()
    
    # 에이전트별 MCP 도구 로드
    mcp_tools = await load_mcp_tools(agent_name=["vulnerability_assessment"])
    
    # 핸드오프 도구 정의 (다른 에이전트로 작업 전달)
    handoff_tools = [
        handoff_to_planner,
        handoff_to_summary,
        # 필요한 경우 다른 전문 에이전트로의 핸드오프 추가
    ]
    
    # 메모리 도구 (장기 기억 및 검색)
    memory_tools = [
        create_manage_memory_tool(namespace=("memories",)),
        create_search_memory_tool(namespace=("memories",))
    ]
    
    # 모든 도구 통합
    tools = mcp_tools + handoff_tools + memory_tools
    
    # 에이전트 생성
    agent = create_react_agent(
        llm,
        tools=tools,
        store=store,
        name="VulnerabilityAssessment",
        prompt=load_prompt("vulnerability_assessment", "swarm")
    )
    
    return agent
]]></correct-example>
<incorrect-example title="불완전한 에이전트 구현" conditions="새로운 에이전트 생성" expected-result="표준화된 에이전트" incorrectness-criteria="필수 도구 누락"><![CDATA[
from langgraph.prebuilt import create_react_agent

def make_simple_agent():
    """불완전한 에이전트 (표준 누락)"""
    llm = ChatOpenAI(temperature=0)
    
    # MCP 도구, 메모리 도구, 핸드오프 도구 누락
    tools = [some_basic_tool]
    
    agent = create_react_agent(
        llm,
        tools=tools,
        name="SimpleAgent"
        # store, prompt 누락
    )
    
    return agent
]]></incorrect-example>
</example>
</examples>
</requirement>

<requirement priority="high">
<description>에이전트 간 핸드오프는 명확한 컨텍스트와 함께 수행하며, 작업 상태를 전달한다.</description>
<examples>
<example title="에이전트 핸드오프 패턴">
<correct-example title="컨텍스트가 포함된 핸드오프" conditions="에이전트 간 작업 전달" expected-result="매끄러운 작업 흐름" correctness-criteria="명확한 컨텍스트와 상태 전달"><![CDATA[
from typing import Dict, Any, List
from langchain_core.messages import BaseMessage

async def handoff_to_exploitation_agent(
    current_findings: Dict[str, Any],
    target_info: Dict[str, str],
    context: str = "Vulnerability assessment completed"
) -> Dict[str, Any]:
    """취약점 발견 후 익스플로잇 에이전트로 핸드오프"""
    
    # 핸드오프 컨텍스트 구성
    handoff_context = {
        "from_agent": "vulnerability_assessment",
        "to_agent": "exploitation",
        "context": context,
        "timestamp": datetime.now().isoformat(),
        
        # 발견된 취약점 정보
        "findings": {
            "vulnerabilities": current_findings.get("vulnerabilities", []),
            "severity_levels": current_findings.get("severity_levels", {}),
            "exploit_recommendations": current_findings.get("exploit_recommendations", [])
        },
        
        # 타겟 시스템 정보
        "target": {
            "ip_address": target_info.get("ip", ""),
            "open_ports": target_info.get("ports", []),
            "services": target_info.get("services", {}),
            "os_info": target_info.get("os", "")
        },
        
        # 다음 단계 지시사항
        "next_actions": [
            "Prioritize high-severity vulnerabilities",
            "Test exploitability in controlled manner", 
            "Document exploitation attempts"
        ]
    }
    
    # 메모리에 핸드오프 기록 저장
    await save_handoff_record(handoff_context)
    
    return handoff_context

async def receive_handoff_context(handoff_data: Dict[str, Any]) -> str:
    """핸드오프 컨텍스트를 수신하고 처리"""
    from_agent = handoff_data.get("from_agent", "unknown")
    findings = handoff_data.get("findings", {})
    target = handoff_data.get("target", {})
    next_actions = handoff_data.get("next_actions", [])
    
    # 수신된 컨텍스트를 바탕으로 작업 시작 메시지 구성
    context_message = f"""
Received handoff from {from_agent} agent.

Target Information:
- IP Address: {target.get('ip_address')}
- Open Ports: {', '.join(map(str, target.get('open_ports', [])))}
- Services: {', '.join(target.get('services', {}).keys())}

Vulnerability Summary:
- Total Vulnerabilities: {len(findings.get('vulnerabilities', []))}
- High Severity: {findings.get('severity_levels', {}).get('high', 0)}
- Exploit Recommendations: {len(findings.get('exploit_recommendations', []))}

Next Actions:
{chr(10).join(f"- {action}" for action in next_actions)}

Starting exploitation analysis based on provided context.
"""
    
    return context_message
]]></correct-example>
<incorrect-example title="컨텍스트 없는 핸드오프" conditions="에이전트 간 작업 전달" expected-result="매끄러운 작업 흐름" incorrectness-criteria="컨텍스트 정보 누락"><![CDATA[
def simple_handoff():
    """컨텍스트 없는 단순 핸드오프 (정보 손실)"""
    return "Hand off to next agent"
]]></incorrect-example>
</example>
</examples>
</requirement>

<requirement priority="high">
<description>에이전트별 전문성을 명확히 정의하고 역할에 맞는 도구만 제공한다.</description>
<examples>
<example title="에이전트 전문성 정의">
<correct-example title="전문화된 에이전트 역할" conditions="특화 에이전트 개발" expected-result="명확한 역할 분담" correctness-criteria="전문 도구와 명확한 책임"><![CDATA[
class AgentSpecialization:
    """에이전트 전문성 정의"""
    
    RECONNAISSANCE = {
        "name": "Reconnaissance",
        "description": "네트워크 정찰 및 정보 수집 전문",
        "responsibilities": [
            "네트워크 스캔 및 서비스 발견",
            "DNS 정보 수집",
            "웹 애플리케이션 정찰",
            "소셜 엔지니어링 정보 수집"
        ],
        "mcp_tools": ["reconnaissance"],
        "handoff_targets": ["initial_access", "vulnerability_assessment"],
        "memory_namespaces": ["network_intel", "target_info"]
    }
    
    VULNERABILITY_ASSESSMENT = {
        "name": "VulnerabilityAssessment", 
        "description": "취약점 분석 및 평가 전문",
        "responsibilities": [
            "알려진 취약점 스캔",
            "취약점 심각도 평가", 
            "익스플로잇 가능성 분석",
            "패치 상태 확인"
        ],
        "mcp_tools": ["vulnerability_scanner", "cve_database"],
        "handoff_targets": ["exploitation", "reporting"],
        "memory_namespaces": ["vulnerabilities", "cve_data"]
    }
    
    EXPLOITATION = {
        "name": "Exploitation",
        "description": "취약점 익스플로잇 및 시스템 침투 전문", 
        "responsibilities": [
            "취약점 익스플로잇 실행",
            "초기 접근 권한 획득",
            "권한 상승 시도",
            "지속성 확보"
        ],
        "mcp_tools": ["exploit_tools", "payload_generator"],
        "handoff_targets": ["post_exploitation", "reporting"],
        "memory_namespaces": ["exploits", "access_methods"]
    }

async def create_specialized_agent(specialization: Dict[str, Any]) -> Any:
    """전문성에 따른 에이전트 생성"""
    llm = get_current_llm()
    store = get_store()
    
    # 전문 분야에 맞는 MCP 도구만 로드
    mcp_tools = await load_mcp_tools(agent_name=specialization["mcp_tools"])
    
    # 전문 분야별 핸드오프 도구
    handoff_tools = [
        create_handoff_tool(target) 
        for target in specialization["handoff_targets"]
    ]
    
    # 전문 분야별 메모리 네임스페이스
    memory_tools = []
    for namespace in specialization["memory_namespaces"]:
        memory_tools.extend([
            create_manage_memory_tool(namespace=(namespace,)),
            create_search_memory_tool(namespace=(namespace,))
        ])
    
    tools = mcp_tools + handoff_tools + memory_tools
    
    # 전문성에 특화된 프롬프트 로드
    prompt_name = specialization["name"].lower().replace(" ", "_")
    
    agent = create_react_agent(
        llm,
        tools=tools,
        store=store,
        name=specialization["name"],
        prompt=load_prompt(prompt_name, "specialized")
    )
    
    return agent
]]></correct-example>
<incorrect-example title="범용 에이전트" conditions="특화 에이전트 개발" expected-result="명확한 역할 분담" incorrectness-criteria="전문성 없는 범용 에이전트"><![CDATA[
async def create_generic_agent():
    """범용 에이전트 (역할 모호)"""
    llm = get_current_llm()
    
    # 모든 도구를 다 로드 (비효율적)
    all_tools = await load_all_possible_tools()
    
    agent = create_react_agent(
        llm,
        tools=all_tools,
        name="GenericAgent",
        prompt="Do whatever the user asks"  # 명확하지 않은 역할
    )
    
    return agent
]]></incorrect-example>
</example>
</examples>
</requirement>

<requirement priority="medium">
<description>에이전트 성능 모니터링과 상태 추적을 위한 메트릭을 수집한다.</description>
<examples>
<example title="에이전트 모니터링">
<correct-example title="에이전트 성능 추적" conditions="에이전트 실행 모니터링" expected-result="성능 데이터 수집" correctness-criteria="실행 시간, 성공률, 도구 사용량 추적"><![CDATA[
import time
from typing import Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime

@dataclass
class AgentMetrics:
    """에이전트 성능 메트릭"""
    agent_name: str
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None
    task_count: int = 0
    successful_tasks: int = 0
    failed_tasks: int = 0
    tool_usage: Dict[str, int] = field(default_factory=dict)
    memory_operations: int = 0
    handoff_count: int = 0
    
    @property
    def execution_time(self) -> float:
        """실행 시간 계산"""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time
    
    @property 
    def success_rate(self) -> float:
        """성공률 계산"""
        if self.task_count == 0:
            return 0.0
        return self.successful_tasks / self.task_count

class AgentMonitor:
    """에이전트 모니터링 시스템"""
    
    def __init__(self):
        self.metrics: Dict[str, AgentMetrics] = {}
    
    def start_tracking(self, agent_name: str) -> None:
        """에이전트 추적 시작"""
        self.metrics[agent_name] = AgentMetrics(agent_name=agent_name)
    
    def record_task_completion(self, agent_name: str, success: bool) -> None:
        """작업 완료 기록"""
        if agent_name in self.metrics:
            metrics = self.metrics[agent_name]
            metrics.task_count += 1
            if success:
                metrics.successful_tasks += 1
            else:
                metrics.failed_tasks += 1
    
    def record_tool_usage(self, agent_name: str, tool_name: str) -> None:
        """도구 사용 기록"""
        if agent_name in self.metrics:
            metrics = self.metrics[agent_name]
            metrics.tool_usage[tool_name] = metrics.tool_usage.get(tool_name, 0) + 1
    
    def record_handoff(self, from_agent: str, to_agent: str) -> None:
        """핸드오프 기록"""
        if from_agent in self.metrics:
            self.metrics[from_agent].handoff_count += 1
    
    def get_performance_report(self, agent_name: str) -> Dict[str, Any]:
        """성능 보고서 생성"""
        if agent_name not in self.metrics:
            return {"error": f"No metrics found for agent {agent_name}"}
        
        metrics = self.metrics[agent_name]
        
        return {
            "agent_name": agent_name,
            "execution_time": metrics.execution_time,
            "task_statistics": {
                "total_tasks": metrics.task_count,
                "successful_tasks": metrics.successful_tasks,
                "failed_tasks": metrics.failed_tasks,
                "success_rate": f"{metrics.success_rate:.2%}"
            },
            "tool_usage": metrics.tool_usage,
            "memory_operations": metrics.memory_operations,
            "handoff_count": metrics.handoff_count,
            "timestamp": datetime.now().isoformat()
        }

# 글로벌 모니터링 인스턴스
agent_monitor = AgentMonitor()

async def monitored_agent_execution(agent_name: str, task: str) -> Dict[str, Any]:
    """모니터링이 포함된 에이전트 실행"""
    agent_monitor.start_tracking(agent_name)
    
    try:
        # 에이전트 실행
        result = await execute_agent_task(agent_name, task)
        
        # 성공 기록
        agent_monitor.record_task_completion(agent_name, True)
        
        return {
            "status": "success",
            "result": result,
            "metrics": agent_monitor.get_performance_report(agent_name)
        }
    
    except Exception as e:
        # 실패 기록
        agent_monitor.record_task_completion(agent_name, False)
        
        return {
            "status": "error",
            "error": str(e),
            "metrics": agent_monitor.get_performance_report(agent_name)
        }
]]></correct-example>
<incorrect-example title="모니터링 없는 실행" conditions="에이전트 실행 모니터링" expected-result="성능 데이터 수집" incorrectness-criteria="성능 추적 누락"><![CDATA[
async def unmonitored_agent_execution(agent_name: str, task: str) -> Any:
    """모니터링 없는 에이전트 실행"""
    # 성능 추적, 메트릭 수집 없이 단순 실행
    result = await execute_agent_task(agent_name, task)
    return result
]]></incorrect-example>
</example>
</examples>
</requirement>

<non-negotiable priority="critical">
<description>에이전트는 보안 가이드라인을 준수하며, 위험한 작업 전에 사용자 확인을 받는다.</description>
<examples>
<example title="에이전트 보안 가이드라인">
<correct-example title="안전한 에이전트 동작" conditions="위험한 보안 작업 수행" expected-result="안전한 작업 실행" correctness-criteria="사용자 확인과 안전 장치"><![CDATA[
from enum import Enum
from typing import List, Dict, Any

class RiskLevel(Enum):
    """작업 위험도 레벨"""
    LOW = "low"           # 정보 수집, 스캔
    MEDIUM = "medium"     # 취약점 테스트
    HIGH = "high"         # 익스플로잇 시도
    CRITICAL = "critical" # 시스템 변경

class SecurityGuardian:
    """에이전트 보안 가이드라인 관리"""
    
    def __init__(self):
        self.risk_assessments = {
            "network_scan": RiskLevel.LOW,
            "port_scan": RiskLevel.LOW,
            "vulnerability_scan": RiskLevel.MEDIUM,
            "exploit_attempt": RiskLevel.HIGH,
            "privilege_escalation": RiskLevel.HIGH,
            "system_modification": RiskLevel.CRITICAL
        }
        
        self.approval_required = {
            RiskLevel.LOW: False,
            RiskLevel.MEDIUM: False,
            RiskLevel.HIGH: True,
            RiskLevel.CRITICAL: True
        }
    
    async def assess_action_risk(self, action: str, target: str) -> Dict[str, Any]:
        """작업 위험도 평가"""
        risk_level = self.risk_assessments.get(action, RiskLevel.MEDIUM)
        
        assessment = {
            "action": action,
            "target": target,
            "risk_level": risk_level.value,
            "approval_required": self.approval_required[risk_level],
            "timestamp": datetime.now().isoformat()
        }
        
        # 추가 위험 요소 검사
        if self._is_production_system(target):
            assessment["risk_level"] = RiskLevel.CRITICAL.value
            assessment["approval_required"] = True
            assessment["warning"] = "Production system detected"
        
        return assessment
    
    def _is_production_system(self, target: str) -> bool:
        """프로덕션 시스템 여부 판단"""
        production_indicators = [
            "prod", "production", "live", "www", "mail", "db"
        ]
        return any(indicator in target.lower() for indicator in production_indicators)

async def secure_agent_action(
    agent_name: str,
    action: str, 
    target: str,
    user_id: str,
    **kwargs
) -> Dict[str, Any]:
    """보안 가이드라인을 준수하는 에이전트 작업"""
    guardian = SecurityGuardian()
    
    # 위험도 평가
    risk_assessment = await guardian.assess_action_risk(action, target)
    
    # 높은 위험도 작업은 사용자 승인 필요
    if risk_assessment["approval_required"]:
        approval_request = {
            "action": action,
            "target": target,
            "risk_level": risk_assessment["risk_level"],
            "warning": risk_assessment.get("warning"),
            "details": f"Agent '{agent_name}' requests permission to perform '{action}' on '{target}'"
        }
        
        # 사용자 승인 대기 (실제 구현에서는 UI를 통해 처리)
        user_approved = await request_user_approval(approval_request, user_id)
        
        if not user_approved:
            return {
                "status": "denied",
                "reason": "User denied approval for high-risk action",
                "risk_assessment": risk_assessment
            }
    
    # 승인되었거나 저위험 작업인 경우 실행
    try:
        # 안전 장치와 함께 작업 실행
        result = await execute_with_safety_checks(action, target, **kwargs)
        
        # 작업 로그 기록
        await log_security_action(agent_name, action, target, "success", user_id)
        
        return {
            "status": "completed",
            "result": result,
            "risk_assessment": risk_assessment
        }
    
    except Exception as e:
        # 실패 로그 기록
        await log_security_action(agent_name, action, target, "failed", user_id)
        
        return {
            "status": "failed",
            "error": str(e),
            "risk_assessment": risk_assessment
        }

async def request_user_approval(request: Dict[str, Any], user_id: str) -> bool:
    """사용자 승인 요청 (실제 구현에서는 UI 연동)"""
    # 실제 환경에서는 웹 UI나 CLI를 통해 사용자 승인을 받음
    print(f"🚨 HIGH RISK ACTION DETECTED 🚨")
    print(f"Action: {request['action']}")
    print(f"Target: {request['target']}")
    print(f"Risk Level: {request['risk_level']}")
    if request.get('warning'):
        print(f"Warning: {request['warning']}")
    
    # 임시: 자동 승인 (실제로는 사용자 입력 대기)
    return True
]]></correct-example>
<incorrect-example title="보안 검증 없는 실행" conditions="위험한 보안 작업 수행" expected-result="안전한 작업 실행" incorrectness-criteria="위험도 평가 및 승인 과정 누락"><![CDATA[
async def unsafe_agent_action(action: str, target: str, **kwargs) -> Any:
    """보안 검증 없는 위험한 실행"""
    # 위험도 평가, 사용자 승인, 안전 장치 없이 바로 실행
    result = await execute_action(action, target, **kwargs)
    return result
]]></incorrect-example>
</example>
</examples>
</non-negotiable>
</requirements>

<context description="AI 에이전트 개발 컨텍스트">
Decepticon의 AI 에이전트들은 각자 전문 분야를 가지고 협력하여 복잡한 보안 테스팅 작업을 수행합니다.
에이전트 간의 원활한 협력과 안전한 보안 도구 실행이 핵심이며, 
사용자의 명시적 승인 없이는 위험한 작업을 수행하지 않도록 설계되어야 합니다.
메모리 시스템을 통해 학습하고 발전하는 지능적인 에이전트 구축이 목표입니다.
</context>

<references>
<reference as="dependency" href=".cursor/rules/main-project-rules.mdc" reason="기본 프로젝트 규칙">메인 프로젝트 규칙</reference>
<reference as="dependency" href=".cursor/rules/langchain-langgraph.mdc" reason="LangGraph 기반 에이전트">LangChain/LangGraph 개발 규칙</reference>
<reference as="context" href=".cursor/rules/mcp-integration.mdc" reason="MCP 도구 통합">MCP 통합 규칙</reference>
<reference as="context" href=".cursor/rules/security-pentesting.mdc" reason="보안 도구 사용">보안 및 펜테스팅 규칙</reference>
</references>
</rule>
