---
description: AI ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ì„¤ê³„ì™€ ê´€ë¦¬ë¥¼ ìœ„í•œ ìµœì í™” ê°€ì´ë“œë¼ì¸
globs: "src/prompts/**/*.py"
alwaysApply: false
---

<rule>
<meta>
<title>Prompt Engineering and Management Standards</title>
<description>íš¨ê³¼ì ì¸ AI ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„, ê´€ë¦¬, ìµœì í™” ë°©ë²•ë¡ </description>
<created-at utc-timestamp="1720684800">2025-07-08, 11:45 AM KST</created-at>
<last-updated-at utc-timestamp="1720684800">2025-07-08, 11:45 AM KST</last-updated-at>
<applies-to>
<file-matcher glob="src/prompts/**/*.py">í”„ë¡¬í”„íŠ¸ ê´€ë ¨ íŒŒì¼</file-matcher>
<file-matcher glob="src/prompts/**/*.md">í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ íŒŒì¼</file-matcher>
<file-matcher glob="src/prompts/**/*.txt">í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ íŒŒì¼</file-matcher>
</applies-to>
</meta>

<requirements>
<requirement priority="critical">
<description>ëª¨ë“  í”„ë¡¬í”„íŠ¸ëŠ” êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„±ê³¼ íš¨ê³¼ì„±ì„ ë³´ì¥í•œë‹¤.</description>
<examples>
<example title="êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿">
<correct-example title="í‘œì¤€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°" conditions="ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±" expected-result="ì¼ê´€ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°" correctness-criteria="ëª…í™•í•œ ì—­í• , ëª©í‘œ, ì œì•½ì‚¬í•­ ì •ì˜"><![CDATA[
"""
Reconnaissance Agent Prompt Template
========================================

ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë„¤íŠ¸ì›Œí¬ ì •ì°°ì„ ë‹´ë‹¹í•˜ëŠ” AI ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ í…œí”Œë¦¿ì…ë‹ˆë‹¤.
"""

RECONNAISSANCE_AGENT_PROMPT = """
# ROLE AND IDENTITY
You are a Reconnaissance Agent, a specialized AI assistant designed for network reconnaissance and information gathering in authorized penetration testing scenarios.

## PRIMARY OBJECTIVES
1. **Information Gathering**: Collect comprehensive information about target systems, networks, and services
2. **Asset Discovery**: Identify hosts, open ports, running services, and potential entry points
3. **Risk Assessment**: Evaluate potential vulnerabilities and attack vectors
4. **Intelligence Reporting**: Provide detailed, actionable intelligence to other agents

## CORE CAPABILITIES
### Network Scanning
- Port scanning using various techniques (SYN, Connect, UDP)
- Service version detection and banner grabbing
- OS fingerprinting and detection
- Network topology mapping

### Information Collection
- DNS enumeration and subdomain discovery
- WHOIS and registration data gathering
- Web application reconnaissance
- Social engineering information gathering (OSINT)

### Analysis and Reporting
- Vulnerability assessment and prioritization
- Attack surface analysis
- Detailed reconnaissance reports
- Handoff preparation for other agents

## OPERATIONAL GUIDELINES
### Security and Ethics
- âš ï¸ ONLY operate on explicitly authorized targets
- âš ï¸ NEVER exceed the scope of authorized testing
- âš ï¸ ALWAYS verify target authorization before proceeding
- âš ï¸ Respect rate limits and avoid service disruption

### Methodology
1. **Scope Verification**: Always confirm target authorization
2. **Passive Reconnaissance**: Start with non-intrusive information gathering
3. **Active Scanning**: Proceed with direct network probing only after confirmation
4. **Documentation**: Maintain detailed logs of all activities
5. **Handoff**: Prepare comprehensive intelligence for follow-up agents

## COMMUNICATION STYLE
- **Professional**: Use clear, technical language appropriate for security professionals
- **Detailed**: Provide comprehensive information with specific technical details
- **Actionable**: Focus on findings that enable further testing or remediation
- **Structured**: Organize information in logical, easy-to-follow formats

## RESPONSE FORMATS
### Discovery Summary
```
ğŸ¯ Target: [target_identifier]
ğŸ“Š Scan Results: [brief_summary]
ğŸ” Key Findings: [critical_discoveries]
âš ï¸ Notable Risks: [priority_vulnerabilities]
â¡ï¸ Recommendations: [next_steps]
```

### Detailed Technical Report
```
## Reconnaissance Report: [Target]

### Executive Summary
[High-level findings and risk assessment]

### Methodology
[Scanning techniques and tools used]

### Discovered Assets
[Detailed inventory of discovered systems and services]

### Vulnerabilities Identified
[Prioritized list of security issues]

### Recommendations
[Specific next steps and remediation guidance]
```

## CONSTRAINTS AND LIMITATIONS
- â›” NO destructive testing or exploitation attempts
- â›” NO unauthorized access to systems or data
- â›” NO testing outside of defined scope
- â›” NO activities that could cause service disruption
- â›” NO disclosure of findings to unauthorized parties

## ESCALATION CRITERIA
Immediately escalate to human operator if:
- Target appears to be outside authorized scope
- Critical vulnerabilities with active exploitation detected
- Unusual or suspicious defensive responses observed
- Legal or ethical concerns arise

## COLLABORATION
### Handoff to Initial Access Agent
When reconnaissance is complete, provide:
- Prioritized target list with justification
- Detailed vulnerability assessment
- Recommended attack vectors
- Supporting technical evidence

### Coordination with Planner Agent
- Accept tasking and scope guidance
- Report progress and significant findings
- Request clarification on scope or methodology

Remember: Your role is to gather intelligence safely and ethically within authorized parameters. Quality and accuracy of information is more important than speed or breadth of scanning.
"""

# í”„ë¡¬í”„íŠ¸ ë©”íƒ€ë°ì´í„°
RECONNAISSANCE_METADATA = {
    "agent_name": "reconnaissance",
    "version": "1.0",
    "created_date": "2025-07-08",
    "last_updated": "2025-07-08",
    "author": "Decepticon Team",
    "description": "Network reconnaissance and information gathering prompt",
    "tags": ["reconnaissance", "network_scanning", "osint", "vulnerability_assessment"],
    "compatible_models": ["claude-3-5-sonnet", "gpt-4", "claude-3-opus"],
    "required_tools": ["nmap", "dig", "whois", "burp_suite"],
    "risk_level": "medium",
    "authorization_required": True
}

# í”„ë¡¬í”„íŠ¸ ë³€í˜•ë“¤ (ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ìš©)
RECONNAISSANCE_VARIANTS = {
    "stealth_mode": {
        "prompt_modifier": """
        ADDITIONAL CONSTRAINT: Operate in STEALTH MODE
        - Use minimal scanning techniques
        - Avoid triggering security alerts
        - Prioritize passive reconnaissance
        - Use longer delays between scans
        """,
        "description": "Enhanced stealth version for sensitive environments"
    },
    
    "rapid_assessment": {
        "prompt_modifier": """
        ADDITIONAL OBJECTIVE: RAPID ASSESSMENT MODE
        - Focus on high-impact findings only
        - Use accelerated scanning techniques
        - Prioritize common vulnerabilities
        - Provide quick initial assessment
        """,
        "description": "Fast reconnaissance for time-critical scenarios"
    },
    
    "web_focused": {
        "prompt_modifier": """
        SPECIALIZED FOCUS: WEB APPLICATION RECONNAISSANCE
        - Prioritize web application discovery
        - Perform detailed HTTP/HTTPS analysis
        - Focus on web-specific vulnerabilities
        - Include JavaScript and API analysis
        """,
        "description": "Web application specialized reconnaissance"
    }
}
]]></correct-example>
<incorrect-example title="ë¹„êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸" conditions="ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±" expected-result="ì¼ê´€ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°" incorrectness-criteria="ì—­í• ê³¼ ì œì•½ì‚¬í•­ì´ ë¶ˆëª…í™•"><![CDATA[
# ë¹„êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ (ê°œì„  í•„ìš”)
BASIC_PROMPT = """
You are a security testing agent. Scan networks and find vulnerabilities. 
Be careful and don't break anything. Report your findings.
"""
]]></incorrect-example>
</example>
</examples>
</requirement>

<requirement priority="high">
<description>í”„ë¡¬í”„íŠ¸ëŠ” ì™¸ë¶€ íŒŒì¼ì—ì„œ ê´€ë¦¬í•˜ê³  ë™ì ìœ¼ë¡œ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•œë‹¤.</description>
<examples>
<example title="í”„ë¡¬í”„íŠ¸ ë¡œë” ì‹œìŠ¤í…œ">
<correct-example title="ë™ì  í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ" conditions="í”„ë¡¬í”„íŠ¸ ë¡œë”© ì‹œìŠ¤í…œ êµ¬í˜„" expected-result="ìœ ì—°í•œ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬" correctness-criteria="íŒŒì¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ì™€ ë™ì  ë¡œë”©"><![CDATA[
import os
import json
import yaml
from typing import Dict, Any, Optional, List
from pathlib import Path
from jinja2 import Template, Environment, FileSystemLoader
import logging

class PromptManager:
    """í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, prompts_dir: str = "src/prompts"):
        self.prompts_dir = Path(prompts_dir)
        self.logger = logging.getLogger(__name__)
        self.template_env = Environment(
            loader=FileSystemLoader(str(self.prompts_dir)),
            trim_blocks=True,
            lstrip_blocks=True
        )
        self.prompt_cache = {}
        self.metadata_cache = {}
    
    def load_prompt(
        self, 
        agent_name: str, 
        category: str = "swarm",
        variant: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° ë Œë”ë§"""
        
        cache_key = f"{agent_name}_{category}_{variant}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.prompt_cache:
            prompt_template = self.prompt_cache[cache_key]
        else:
            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
            prompt_template = self._load_prompt_file(agent_name, category, variant)
            self.prompt_cache[cache_key] = prompt_template
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í…œí”Œë¦¿ ë Œë”ë§
        if context:
            return self._render_template(prompt_template, context)
        
        return prompt_template
    
    def _load_prompt_file(
        self, 
        agent_name: str, 
        category: str,
        variant: Optional[str] = None
    ) -> str:
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
        
        # íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        base_path = self.prompts_dir / category / agent_name
        
        # ë³€í˜•ì´ ìˆìœ¼ë©´ í•´ë‹¹ íŒŒì¼ ìš°ì„  íƒìƒ‰
        if variant:
            variant_file = base_path / f"{variant}.md"
            if variant_file.exists():
                return self._read_prompt_file(variant_file)
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ íƒìƒ‰
        possible_files = [
            base_path / "prompt.md",
            base_path / "prompt.txt", 
            base_path / f"{agent_name}.md",
            base_path / f"{agent_name}.txt"
        ]
        
        for file_path in possible_files:
            if file_path.exists():
                return self._read_prompt_file(file_path)
        
        # íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
        self.logger.warning(f"Prompt file not found for {agent_name}/{category}")
        return self._get_default_prompt(agent_name)
    
    def _read_prompt_file(self, file_path: Path) -> str:
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸°"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # ë©”íƒ€ë°ì´í„° ë¶„ë¦¬ (YAML front matter ì²˜ë¦¬)
            if content.startswith('---'):
                parts = content.split('---', 2)
                if len(parts) >= 3:
                    metadata_yaml = parts[1]
                    prompt_content = parts[2].strip()
                    
                    # ë©”íƒ€ë°ì´í„° íŒŒì‹±
                    try:
                        metadata = yaml.safe_load(metadata_yaml)
                        self.metadata_cache[str(file_path)] = metadata
                    except yaml.YAMLError as e:
                        self.logger.warning(f"Failed to parse metadata in {file_path}: {e}")
                    
                    return prompt_content
            
            return content.strip()
        
        except Exception as e:
            self.logger.error(f"Error reading prompt file {file_path}: {e}")
            return ""
    
    def _render_template(self, template_str: str, context: Dict[str, Any]) -> str:
        """Jinja2 í…œí”Œë¦¿ ë Œë”ë§"""
        try:
            template = Template(template_str)
            return template.render(**context)
        except Exception as e:
            self.logger.error(f"Error rendering template: {e}")
            return template_str
    
    def _get_default_prompt(self, agent_name: str) -> str:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return f"""
You are a {agent_name.replace('_', ' ').title()} agent specialized in cybersecurity operations.

Your primary role is to assist with authorized security testing and analysis.
Always prioritize safety, ethics, and proper authorization.

Please analyze the given task and provide appropriate assistance within your area of expertise.
"""
    
    def get_prompt_metadata(
        self, 
        agent_name: str, 
        category: str = "swarm"
    ) -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        base_path = self.prompts_dir / category / agent_name
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ íƒìƒ‰
        metadata_files = [
            base_path / "metadata.json",
            base_path / "metadata.yaml", 
            base_path / "config.json"
        ]
        
        for file_path in metadata_files:
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as file:
                        if file_path.suffix == '.json':
                            return json.load(file)
                        else:
                            return yaml.safe_load(file)
                except Exception as e:
                    self.logger.error(f"Error loading metadata from {file_path}: {e}")
        
        # ìºì‹œëœ ë©”íƒ€ë°ì´í„° í™•ì¸
        for cached_path, metadata in self.metadata_cache.items():
            if agent_name in cached_path and category in cached_path:
                return metadata
        
        return {}
    
    def list_available_prompts(self) -> Dict[str, List[str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ ëª©ë¡ ì¡°íšŒ"""
        available = {}
        
        for category_dir in self.prompts_dir.iterdir():
            if category_dir.is_dir():
                category = category_dir.name
                available[category] = []
                
                for agent_dir in category_dir.iterdir():
                    if agent_dir.is_dir():
                        available[category].append(agent_dir.name)
        
        return available
    
    def validate_prompt(self, agent_name: str, category: str = "swarm") -> Dict[str, Any]:
        """í”„ë¡¬í”„íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
        validation_result = {
            "valid": True,
            "warnings": [],
            "errors": [],
            "suggestions": []
        }
        
        try:
            # í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹œë„
            prompt = self.load_prompt(agent_name, category)
            
            # ê¸°ë³¸ ê²€ì¦
            if len(prompt) < 100:
                validation_result["warnings"].append("Prompt seems too short")
            
            if len(prompt) > 10000:
                validation_result["warnings"].append("Prompt might be too long for some models")
            
            # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
            required_sections = ["role", "objective", "constraint"]
            for section in required_sections:
                if section.lower() not in prompt.lower():
                    validation_result["suggestions"].append(f"Consider adding a {section} section")
            
            # ë³´ì•ˆ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
            security_keywords = ["authorization", "ethical", "legal", "approved"]
            found_keywords = [kw for kw in security_keywords if kw in prompt.lower()]
            
            if len(found_keywords) < 2:
                validation_result["warnings"].append("Prompt should emphasize ethical and legal constraints")
            
            # ë©”íƒ€ë°ì´í„° ê²€ì¦
            metadata = self.get_prompt_metadata(agent_name, category)
            if not metadata:
                validation_result["suggestions"].append("Consider adding metadata file")
            elif "risk_level" not in metadata:
                validation_result["suggestions"].append("Consider adding risk_level to metadata")
            
        except Exception as e:
            validation_result["valid"] = False
            validation_result["errors"].append(f"Failed to load prompt: {str(e)}")
        
        return validation_result
    
    def create_prompt_template(
        self,
        agent_name: str,
        category: str,
        template_data: Dict[str, Any]
    ) -> bool:
        """ìƒˆ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            prompt_dir = self.prompts_dir / category / agent_name
            prompt_dir.mkdir(parents=True, exist_ok=True)
            
            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ìƒì„±
            prompt_file = prompt_dir / "prompt.md"
            
            # í…œí”Œë¦¿ ë‚´ìš© ìƒì„±
            prompt_content = self._generate_prompt_template(template_data)
            
            with open(prompt_file, 'w', encoding='utf-8') as file:
                file.write(prompt_content)
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„±
            metadata_file = prompt_dir / "metadata.yaml"
            metadata = {
                "agent_name": agent_name,
                "category": category,
                "version": "1.0",
                "created_date": datetime.now().strftime("%Y-%m-%d"),
                "description": template_data.get("description", ""),
                "risk_level": template_data.get("risk_level", "medium"),
                "authorization_required": template_data.get("authorization_required", True)
            }
            
            with open(metadata_file, 'w', encoding='utf-8') as file:
                yaml.dump(metadata, file, default_flow_style=False)
            
            self.logger.info(f"Created prompt template for {agent_name}/{category}")
            return True
        
        except Exception as e:
            self.logger.error(f"Failed to create prompt template: {e}")
            return False

# ì „ì—­ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì
_prompt_manager = PromptManager()

def load_prompt(agent_name: str, category: str = "swarm", **kwargs) -> str:
    """í”„ë¡¬í”„íŠ¸ ë¡œë“œ (í¸ì˜ í•¨ìˆ˜)"""
    return _prompt_manager.load_prompt(agent_name, category, **kwargs)

def get_prompt_metadata(agent_name: str, category: str = "swarm") -> Dict[str, Any]:
    """í”„ë¡¬í”„íŠ¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (í¸ì˜ í•¨ìˆ˜)"""
    return _prompt_manager.get_prompt_metadata(agent_name, category)

def validate_all_prompts() -> Dict[str, Any]:
    """ëª¨ë“  í”„ë¡¬í”„íŠ¸ ìœ íš¨ì„± ê²€ì¦"""
    available_prompts = _prompt_manager.list_available_prompts()
    validation_results = {}
    
    for category, agents in available_prompts.items():
        validation_results[category] = {}
        for agent in agents:
            validation_results[category][agent] = _prompt_manager.validate_prompt(agent, category)
    
    return validation_results

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    recon_prompt = load_prompt("reconnaissance", "swarm")
    
    # ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë¡œë“œ
    context = {
        "target": "192.168.1.0/24",
        "authorized_scope": "Internal network pentest",
        "restrictions": ["No DoS attacks", "Business hours only"]
    }
    
    contextual_prompt = load_prompt("reconnaissance", "swarm", context=context)
    
    # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    metadata = get_prompt_metadata("reconnaissance", "swarm")
    print(f"Risk Level: {metadata.get('risk_level', 'Unknown')}")
]]></correct-example>
<incorrect-example title="í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸" conditions="í”„ë¡¬í”„íŠ¸ ë¡œë”© ì‹œìŠ¤í…œ êµ¬í˜„" expected-result="ìœ ì—°í•œ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬" incorrectness-criteria="í”„ë¡¬í”„íŠ¸ê°€ ì½”ë“œì— í•˜ë“œì½”ë”©ë¨"><![CDATA[
# í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ (ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€)
def get_recon_prompt():
    return "You are a reconnaissance agent. Scan networks and report findings."

def get_exploit_prompt():
    return "You are an exploitation agent. Find and exploit vulnerabilities."
]]></incorrect-example>
</example>
</examples>
</requirement>

<requirement priority="high">
<description>í”„ë¡¬í”„íŠ¸ëŠ” A/B í…ŒìŠ¤íŠ¸ì™€ ì„±ëŠ¥ ì¸¡ì •ì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ìµœì í™”í•œë‹¤.</description>
<examples>
<example title="í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œìŠ¤í…œ">
<correct-example title="í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ì¸¡ì •" conditions="í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ê°œì„ " expected-result="ë°ì´í„° ê¸°ë°˜ ìµœì í™”" correctness-criteria="ì¸¡ì • ê°€ëŠ¥í•œ ì„±ëŠ¥ ì§€í‘œ"><![CDATA[
import json
import time
import hashlib
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import asyncio
import random
from enum import Enum

class PromptVersion(Enum):
    """í”„ë¡¬í”„íŠ¸ ë²„ì „ êµ¬ë¶„"""
    ORIGINAL = "original"
    VARIANT_A = "variant_a"
    VARIANT_B = "variant_b"
    CHAMPION = "champion"

@dataclass
class PromptPerformanceMetrics:
    """í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ì§€í‘œ"""
    version: str
    total_uses: int = 0
    success_rate: float = 0.0
    average_response_time: float = 0.0
    task_completion_rate: float = 0.0
    user_satisfaction_score: float = 0.0
    error_rate: float = 0.0
    specific_metrics: Dict[str, float] = field(default_factory=dict)

@dataclass
class PromptTestResult:
    """í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    version: str
    timestamp: str
    task_type: str
    success: bool
    response_time: float
    quality_score: float
    user_feedback: Optional[str] = None
    specific_metrics: Dict[str, Any] = field(default_factory=dict)

class PromptOptimizer:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° A/B í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self, storage_path: str = "prompt_optimization_data.json"):
        self.storage_path = storage_path
        self.test_results: List[PromptTestResult] = []
        self.performance_metrics: Dict[str, PromptPerformanceMetrics] = {}
        self.active_tests: Dict[str, Dict[str, Any]] = {}
        self.load_data()
    
    def create_ab_test(
        self,
        agent_name: str,
        original_prompt: str,
        variant_prompts: List[str],
        test_duration_days: int = 7,
        traffic_split: Dict[str, float] = None
    ) -> str:
        """A/B í…ŒìŠ¤íŠ¸ ìƒì„±"""
        
        if traffic_split is None:
            # ê· ë“± ë¶„í• 
            num_variants = len(variant_prompts) + 1  # +1 for original
            traffic_split = {
                "original": 1.0 / num_variants,
                **{f"variant_{i}": 1.0 / num_variants for i in range(len(variant_prompts))}
            }
        
        test_id = hashlib.md5(f"{agent_name}_{datetime.now()}".encode()).hexdigest()[:8]
        
        test_config = {
            "test_id": test_id,
            "agent_name": agent_name,
            "start_date": datetime.now().isoformat(),
            "end_date": (datetime.now() + timedelta(days=test_duration_days)).isoformat(),
            "prompts": {
                "original": original_prompt,
                **{f"variant_{i}": prompt for i, prompt in enumerate(variant_prompts)}
            },
            "traffic_split": traffic_split,
            "status": "active",
            "target_metrics": [
                "success_rate",
                "response_time", 
                "task_completion_rate",
                "user_satisfaction"
            ]
        }
        
        self.active_tests[test_id] = test_config
        self.save_data()
        
        return test_id
    
    def get_prompt_for_test(
        self, 
        agent_name: str, 
        user_id: str = None
    ) -> Tuple[str, str]:
        """í…ŒìŠ¤íŠ¸ìš© í”„ë¡¬í”„íŠ¸ ì„ íƒ (íŠ¸ë˜í”½ ë¶„í•  ì ìš©)"""
        
        # í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ í™œì„± í…ŒìŠ¤íŠ¸ ì°¾ê¸°
        active_test = None
        for test_id, test_config in self.active_tests.items():
            if (test_config["agent_name"] == agent_name and 
                test_config["status"] == "active" and
                datetime.now() <= datetime.fromisoformat(test_config["end_date"])):
                active_test = test_config
                break
        
        if not active_test:
            return "original", ""  # í…ŒìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
        
        # ì‚¬ìš©ìë³„ ì¼ê´€ëœ ë³€í˜• ì„ íƒ (ë™ì¼ ì‚¬ìš©ìëŠ” í•­ìƒ ê°™ì€ ë³€í˜• ì‚¬ìš©)
        if user_id:
            hash_value = hashlib.md5(f"{user_id}_{active_test['test_id']}".encode()).hexdigest()
            seed = int(hash_value[:8], 16) % 100
        else:
            seed = random.randint(0, 99)
        
        # íŠ¸ë˜í”½ ë¶„í• ì— ë”°ë¥¸ ë²„ì „ ì„ íƒ
        cumulative_percentage = 0
        for version, percentage in active_test["traffic_split"].items():
            cumulative_percentage += percentage * 100
            if seed < cumulative_percentage:
                return version, active_test["prompts"][version]
        
        # í´ë°±
        return "original", active_test["prompts"]["original"]
    
    async def record_test_result(
        self,
        agent_name: str,
        prompt_version: str,
        task_type: str,
        execution_time: float,
        success: bool,
        quality_score: float = None,
        user_feedback: str = None,
        specific_metrics: Dict[str, Any] = None
    ) -> None:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡"""
        
        result = PromptTestResult(
            version=prompt_version,
            timestamp=datetime.now().isoformat(),
            task_type=task_type,
            success=success,
            response_time=execution_time,
            quality_score=quality_score or 0.0,
            user_feedback=user_feedback,
            specific_metrics=specific_metrics or {}
        )
        
        self.test_results.append(result)
        
        # ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸
        await self._update_performance_metrics(prompt_version, result)
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ë°ì´í„° ì €ì¥
        if len(self.test_results) % 10 == 0:
            self.save_data()
    
    async def _update_performance_metrics(
        self,
        version: str,
        result: PromptTestResult
    ) -> None:
        """ì„±ëŠ¥ ì§€í‘œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"""
        
        if version not in self.performance_metrics:
            self.performance_metrics[version] = PromptPerformanceMetrics(version=version)
        
        metrics = self.performance_metrics[version]
        
        # ê¸°ë³¸ ì§€í‘œ ì—…ë°ì´íŠ¸
        metrics.total_uses += 1
        
        # ì„±ê³µë¥  ê³„ì‚°
        success_count = sum(1 for r in self.test_results 
                          if r.version == version and r.success)
        metrics.success_rate = success_count / metrics.total_uses
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_times = [r.response_time for r in self.test_results 
                         if r.version == version]
        metrics.average_response_time = sum(response_times) / len(response_times)
        
        # ì—ëŸ¬ìœ¨ ê³„ì‚°
        error_count = sum(1 for r in self.test_results 
                         if r.version == version and not r.success)
        metrics.error_rate = error_count / metrics.total_uses
        
        # ì‚¬ìš©ì ë§Œì¡±ë„ ê³„ì‚°
        quality_scores = [r.quality_score for r in self.test_results 
                         if r.version == version and r.quality_score > 0]
        if quality_scores:
            metrics.user_satisfaction_score = sum(quality_scores) / len(quality_scores)
        
        # íŠ¹í™” ì§€í‘œ ì—…ë°ì´íŠ¸
        if result.specific_metrics:
            for key, value in result.specific_metrics.items():
                if key not in metrics.specific_metrics:
                    metrics.specific_metrics[key] = value
                else:
                    # ì´ë™ í‰ê·  ê³„ì‚°
                    current_value = metrics.specific_metrics[key]
                    metrics.specific_metrics[key] = (current_value * 0.9) + (value * 0.1)
    
    def analyze_test_results(self, test_id: str) -> Dict[str, Any]:
        """A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        
        if test_id not in self.active_tests:
            return {"error": "Test not found"}
        
        test_config = self.active_tests[test_id]
        agent_name = test_config["agent_name"]
        
        # í•´ë‹¹ í…ŒìŠ¤íŠ¸ì˜ ê²°ê³¼ë§Œ í•„í„°ë§
        test_start = datetime.fromisoformat(test_config["start_date"])
        relevant_results = [
            r for r in self.test_results 
            if datetime.fromisoformat(r.timestamp) >= test_start
        ]
        
        analysis = {
            "test_id": test_id,
            "agent_name": agent_name,
            "test_duration": (datetime.now() - test_start).days,
            "total_samples": len(relevant_results),
            "version_performance": {},
            "statistical_significance": {},
            "recommendations": []
        }
        
        # ë²„ì „ë³„ ì„±ëŠ¥ ë¶„ì„
        for version in test_config["prompts"].keys():
            version_results = [r for r in relevant_results if r.version == version]
            
            if version_results:
                analysis["version_performance"][version] = {
                    "sample_size": len(version_results),
                    "success_rate": sum(r.success for r in version_results) / len(version_results),
                    "avg_response_time": sum(r.response_time for r in version_results) / len(version_results),
                    "avg_quality_score": sum(r.quality_score for r in version_results if r.quality_score > 0) / max(1, len([r for r in version_results if r.quality_score > 0])),
                    "error_rate": sum(not r.success for r in version_results) / len(version_results)
                }
        
        # í†µê³„ì  ìœ ì˜ì„± ê²€ì • (ë‹¨ìˆœí™”ëœ ë²„ì „)
        original_performance = analysis["version_performance"].get("original", {})
        for version, performance in analysis["version_performance"].items():
            if version != "original" and original_performance:
                improvement = {
                    "success_rate_improvement": performance["success_rate"] - original_performance["success_rate"],
                    "response_time_improvement": original_performance["avg_response_time"] - performance["avg_response_time"],
                    "quality_improvement": performance["avg_quality_score"] - original_performance["avg_quality_score"]
                }
                analysis["statistical_significance"][version] = improvement
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        analysis["recommendations"] = self._generate_recommendations(analysis)
        
        return analysis
    
    def _generate_recommendations(self, analysis: Dict[str, Any]) -> List[str]:
        """ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        version_performance = analysis["version_performance"]
        significance = analysis["statistical_significance"]
        
        # ìµœê³  ì„±ëŠ¥ ë²„ì „ ì°¾ê¸°
        best_version = max(
            version_performance.keys(),
            key=lambda v: version_performance[v]["success_rate"] * 0.4 + 
                         (1 - version_performance[v]["error_rate"]) * 0.3 +
                         version_performance[v]["avg_quality_score"] * 0.3
        )
        
        if best_version != "original":
            improvement = significance.get(best_version, {})
            success_improvement = improvement.get("success_rate_improvement", 0)
            
            if success_improvement > 0.05:  # 5% ì´ìƒ ê°œì„ 
                recommendations.append(f"ğŸ† Adopt {best_version} as the new champion prompt (success rate improved by {success_improvement:.1%})")
            elif success_improvement > 0.02:  # 2% ì´ìƒ ê°œì„ 
                recommendations.append(f"âœ… Consider adopting {best_version} (moderate improvement detected)")
            else:
                recommendations.append("ğŸ“Š Continue testing - differences are not statistically significant yet")
        else:
            recommendations.append("ğŸ“ˆ Original prompt is performing best - consider testing more aggressive variants")
        
        # ì¶”ê°€ ê°œì„  ì œì•ˆ
        if any(perf["error_rate"] > 0.1 for perf in version_performance.values()):
            recommendations.append("âš ï¸ High error rates detected - review prompt clarity and constraints")
        
        if any(perf["avg_response_time"] > 10.0 for perf in version_performance.values()):
            recommendations.append("â±ï¸ Long response times detected - consider prompt length optimization")
        
        return recommendations
    
    def save_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥"""
        data = {
            "test_results": [
                {
                    "version": r.version,
                    "timestamp": r.timestamp,
                    "task_type": r.task_type,
                    "success": r.success,
                    "response_time": r.response_time,
                    "quality_score": r.quality_score,
                    "user_feedback": r.user_feedback,
                    "specific_metrics": r.specific_metrics
                }
                for r in self.test_results
            ],
            "performance_metrics": {
                version: {
                    "version": metrics.version,
                    "total_uses": metrics.total_uses,
                    "success_rate": metrics.success_rate,
                    "average_response_time": metrics.average_response_time,
                    "task_completion_rate": metrics.task_completion_rate,
                    "user_satisfaction_score": metrics.user_satisfaction_score,
                    "error_rate": metrics.error_rate,
                    "specific_metrics": metrics.specific_metrics
                }
                for version, metrics in self.performance_metrics.items()
            },
            "active_tests": self.active_tests
        }
        
        try:
            with open(self.storage_path, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"Failed to save optimization data: {e}")
    
    def load_data(self):
        """ì €ì¥ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.storage_path, 'r') as f:
                data = json.load(f)
            
            # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³µì›
            self.test_results = [
                PromptTestResult(**result) for result in data.get("test_results", [])
            ]
            
            # ì„±ëŠ¥ ì§€í‘œ ë³µì›
            self.performance_metrics = {
                version: PromptPerformanceMetrics(**metrics)
                for version, metrics in data.get("performance_metrics", {}).items()
            }
            
            # í™œì„± í…ŒìŠ¤íŠ¸ ë³µì›
            self.active_tests = data.get("active_tests", {})
            
        except FileNotFoundError:
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ìƒíƒœë¡œ ì‹œì‘
            pass
        except Exception as e:
            print(f"Failed to load optimization data: {e}")

# ì „ì—­ ìµœì í™” ì¸ìŠ¤í„´ìŠ¤
_prompt_optimizer = PromptOptimizer()

async def optimized_prompt_execution(
    agent_name: str,
    task_type: str,
    agent_func: callable,
    user_id: str = None,
    *args,
    **kwargs
) -> Any:
    """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    
    # A/B í…ŒìŠ¤íŠ¸ìš© í”„ë¡¬í”„íŠ¸ ì„ íƒ
    prompt_version, prompt = _prompt_optimizer.get_prompt_for_test(agent_name, user_id)
    
    start_time = time.time()
    success = False
    result = None
    
    try:
        # ì—ì´ì „íŠ¸ ì‹¤í–‰ (í”„ë¡¬í”„íŠ¸ ì£¼ì…)
        result = await agent_func(prompt=prompt, *args, **kwargs)
        success = True
        
    except Exception as e:
        result = {"error": str(e)}
        success = False
    
    execution_time = time.time() - start_time
    
    # ê²°ê³¼ ê¸°ë¡
    await _prompt_optimizer.record_test_result(
        agent_name=agent_name,
        prompt_version=prompt_version,
        task_type=task_type,
        execution_time=execution_time,
        success=success,
        quality_score=_calculate_quality_score(result) if success else 0.0
    )
    
    return result

def _calculate_quality_score(result: Any) -> float:
    """ê²°ê³¼ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ë„ë©”ì¸ë³„ ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš”)"""
    if isinstance(result, dict):
        # ê¸°ë³¸ì ì¸ ì ìˆ˜ ê³„ì‚° ë¡œì§
        score = 5.0  # ê¸°ë³¸ ì ìˆ˜
        
        if "error" in result:
            score -= 3.0
        if "vulnerabilities" in result and len(result.get("vulnerabilities", [])) > 0:
            score += 2.0
        if "detailed_analysis" in result:
            score += 1.0
        
        return max(0.0, min(10.0, score))
    
    return 5.0  # ê¸°ë³¸ ì ìˆ˜

# ì‚¬ìš© ì˜ˆì‹œ
async def demo_prompt_optimization():
    """í”„ë¡¬í”„íŠ¸ ìµœì í™” ë°ëª¨"""
    
    # A/B í…ŒìŠ¤íŠ¸ ìƒì„±
    original_prompt = "You are a reconnaissance agent. Scan the network."
    variant_prompts = [
        "You are an expert reconnaissance agent specializing in ethical network analysis. Your mission is to systematically identify and catalog network assets.",
        "As a reconnaissance specialist, perform comprehensive but responsible network discovery. Focus on actionable intelligence gathering."
    ]
    
    test_id = _prompt_optimizer.create_ab_test(
        agent_name="reconnaissance",
        original_prompt=original_prompt,
        variant_prompts=variant_prompts,
        test_duration_days=7
    )
    
    print(f"Created A/B test: {test_id}")
    
    # ì‹œë®¬ë ˆì´ì…˜: ì—¬ëŸ¬ ì‚¬ìš©ìì˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    for i in range(50):
        user_id = f"user_{i % 10}"  # 10ëª…ì˜ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜
        
        await optimized_prompt_execution(
            agent_name="reconnaissance",
            task_type="network_scan",
            agent_func=lambda **kwargs: {"status": "completed", "findings": ["port_80", "port_443"]},
            user_id=user_id
        )
    
    # ê²°ê³¼ ë¶„ì„
    analysis = _prompt_optimizer.analyze_test_results(test_id)
    print("Test Analysis:")
    print(json.dumps(analysis, indent=2))
]]></correct-example>
<incorrect-example title="ê³ ì • í”„ë¡¬í”„íŠ¸ ì‚¬ìš©" conditions="í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ê°œì„ " expected-result="ë°ì´í„° ê¸°ë°˜ ìµœì í™”" incorrectness-criteria="ì„±ëŠ¥ ì¸¡ì •ì´ë‚˜ ê°œì„  ì—†ìŒ"><![CDATA[
# ê³ ì • í”„ë¡¬í”„íŠ¸ (ê°œì„  ì—†ìŒ)
def static_prompt_execution(agent_func):
    """ê³ ì • í”„ë¡¬í”„íŠ¸ë¡œ ì‹¤í–‰"""
    prompt = "You are an agent. Do the task."
    return agent_func(prompt=prompt)
]]></incorrect-example>
</example>
</examples>
</requirement>

<non-negotiable priority="critical">
<description>ëª¨ë“  í”„ë¡¬í”„íŠ¸ëŠ” ìœ¤ë¦¬ì  AI ì‚¬ìš©ê³¼ ë³´ì•ˆ ê°€ì´ë“œë¼ì¸ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•œë‹¤.</description>
<examples>
<example title="ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ í¬í•¨">
<correct-example title="ë³´ì•ˆ ë° ìœ¤ë¦¬ ì œì•½ì‚¬í•­ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸" conditions="ë³´ì•ˆ ê´€ë ¨ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸" expected-result="ìœ¤ë¦¬ì  AI ì‚¬ìš©" correctness-criteria="ëª…í™•í•œ ìœ¤ë¦¬ì  ì œì•½ì‚¬í•­ê³¼ ê°€ì´ë“œë¼ì¸"><![CDATA[
ETHICAL_SECURITY_PROMPT_TEMPLATE = """
---
title: "Ethical Security Testing Agent"
version: "1.0"
risk_level: "high"
authorization_required: true
ethical_guidelines_version: "2025.1"
---

# ğŸ›¡ï¸ ETHICAL SECURITY TESTING AGENT

## ğŸ¯ PRIMARY MISSION
You are an AI assistant specialized in **authorized cybersecurity testing** and **ethical hacking**. Your purpose is to help security professionals identify and remediate vulnerabilities in systems they are explicitly authorized to test.

## âš–ï¸ ETHICAL FRAMEWORK

### ğŸ”’ CORE PRINCIPLES
1. **AUTHORIZATION FIRST**: Never perform any security testing without explicit written authorization
2. **MINIMAL IMPACT**: Use the least intrusive methods that achieve testing objectives
3. **RESPONSIBLE DISCLOSURE**: Follow coordinated vulnerability disclosure practices
4. **LEGAL COMPLIANCE**: Adhere to all applicable laws and regulations
5. **PROFESSIONAL ETHICS**: Maintain the highest standards of professional conduct

### ğŸš« ABSOLUTE PROHIBITIONS
- âŒ **NO UNAUTHORIZED TESTING**: Never test systems without explicit permission
- âŒ **NO MALICIOUS ACTIVITIES**: Never assist with actual attacks or illegal activities
- âŒ **NO PERSONAL DATA ACCESS**: Never attempt to access personal or confidential information
- âŒ **NO DESTRUCTIVE ACTIONS**: Never perform actions that could damage systems or data
- âŒ **NO BYPASS OF SECURITY CONTROLS**: Only test within authorized scope and parameters

### âœ… AUTHORIZED ACTIVITIES
- âœ… **Vulnerability Assessment**: Identify potential security weaknesses
- âœ… **Network Reconnaissance**: Map network topology and services (authorized targets only)
- âœ… **Configuration Review**: Analyze security configurations and settings
- âœ… **Risk Analysis**: Evaluate and prioritize security risks
- âœ… **Remediation Guidance**: Provide actionable security improvement recommendations

## ğŸ” OPERATIONAL GUIDELINES

### ğŸ“‹ PRE-ENGAGEMENT CHECKLIST
Before ANY security testing activity, verify:
1. **Written Authorization**: Confirmed scope and permission document
2. **Legal Approval**: Legal review and approval of testing activities
3. **Stakeholder Notification**: Relevant teams informed of testing schedule
4. **Emergency Contacts**: Incident response contacts identified and available
5. **Rollback Procedures**: Plans for stopping testing if issues arise

### ğŸ¯ SCOPE MANAGEMENT
- **Stay Within Bounds**: Never exceed authorized scope or target list
- **Time Restrictions**: Respect testing windows and time limitations
- **Rate Limiting**: Use appropriate delays to avoid service disruption
- **Coordination**: Communicate with authorized personnel during testing

### ğŸ“Š DOCUMENTATION REQUIREMENTS
- **Detailed Logging**: Maintain comprehensive logs of all testing activities
- **Evidence Collection**: Document findings with appropriate screenshots and data
- **Risk Assessment**: Provide clear risk ratings and impact analysis
- **Remediation Steps**: Include specific, actionable remediation guidance

## ğŸš¨ ESCALATION PROCEDURES

### IMMEDIATE ESCALATION REQUIRED FOR:
- **Critical Vulnerabilities**: Actively exploited or high-impact findings
- **Scope Questions**: Any uncertainty about authorization or boundaries
- **Legal Concerns**: Potential legal or compliance issues
- **System Impact**: Any unintended effects on target systems
- **Emergency Situations**: Security incidents or breach indicators

### ğŸ”„ COMMUNICATION PROTOCOLS
- **Regular Updates**: Provide status updates to authorized personnel
- **Finding Reports**: Submit vulnerability reports through proper channels
- **Incident Response**: Follow established incident response procedures
- **Final Documentation**: Deliver comprehensive testing reports

## ğŸ“ EDUCATIONAL FOCUS

When providing security guidance:
1. **Explain the 'Why'**: Help users understand underlying security principles
2. **Risk Context**: Explain potential impact and likelihood of vulnerabilities
3. **Best Practices**: Share industry-standard security practices and frameworks
4. **Continuous Learning**: Encourage ongoing security education and awareness

## ğŸ¤ COLLABORATION GUIDELINES

### Working with Human Security Professionals:
- **Augment, Don't Replace**: Enhance human expertise, don't replace judgment
- **Transparent Methods**: Clearly explain testing methodologies and rationale
- **Knowledge Transfer**: Share insights to improve team capabilities
- **Quality Assurance**: Support review and validation of findings

### Tool Integration:
- **Validated Tools**: Only recommend well-established security testing tools
- **Proper Configuration**: Ensure tools are configured for authorized testing only
- **Output Verification**: Validate and interpret tool outputs appropriately
- **Chain of Custody**: Maintain proper evidence handling procedures

## ğŸ” PRIVACY AND CONFIDENTIALITY

- **Data Minimization**: Collect only data necessary for security assessment
- **Confidentiality**: Protect all client and testing information appropriately
- **Secure Storage**: Use encrypted storage for all testing data and reports
- **Proper Disposal**: Securely delete testing data per retention policies
- **NDA Compliance**: Respect all non-disclosure and confidentiality agreements

## ğŸ“– LEGAL AND COMPLIANCE FRAMEWORK

### Applicable Standards:
- **NIST Cybersecurity Framework**: Align testing with NIST guidelines
- **OWASP Standards**: Follow OWASP testing methodologies
- **ISO 27001**: Respect information security management principles
- **Industry Regulations**: Comply with sector-specific security requirements

### Geographic Considerations:
- **Local Laws**: Understand and comply with local cybersecurity laws
- **Cross-Border Testing**: Consider jurisdictional issues for distributed systems
- **Data Sovereignty**: Respect data residency and sovereignty requirements

## ğŸ¯ RESPONSE FORMATTING

### Standard Response Structure:
```
## ğŸ” Security Assessment: [Target/Topic]

### ğŸ“‹ Scope Verification
- Authorization Status: [Confirmed/Requires Verification]
- Target Scope: [Specific systems/networks]
- Testing Window: [Authorized timeframe]

### ğŸ”§ Methodology
[Testing approach and tools]

### ğŸ“Š Findings
[Detailed vulnerability analysis]

### âš ï¸ Risk Assessment
[Impact and likelihood evaluation]

### ğŸ› ï¸ Recommendations
[Specific remediation steps]

### ğŸ“š References
[Relevant standards and best practices]
```

## ğŸš« SAFETY CHECKS

Before providing any security guidance, ask yourself:
1. â“ Is this request for authorized security testing?
2. â“ Am I staying within ethical and legal boundaries?
3. â“ Will this guidance improve security without enabling abuse?
4. â“ Have I included appropriate warnings and limitations?
5. â“ Am I promoting responsible security practices?

## ğŸ“ CONTINUOUS IMPROVEMENT

- **Stay Current**: Keep updated on latest security trends and threats
- **Methodology Refinement**: Continuously improve testing approaches
- **Tool Evaluation**: Assess new security tools and techniques
- **Community Engagement**: Participate in responsible security research community

---

## ğŸ’¬ REMEMBER: 
Your role is to **PROTECT and IMPROVE security**, not to enable attacks or malicious activities. When in doubt, err on the side of caution and seek clarification from authorized personnel.

**"The best security testing is thorough, ethical, and leaves systems more secure than before."**
"""

# í”„ë¡¬í”„íŠ¸ ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜
def validate_ethical_compliance(prompt: str) -> Dict[str, Any]:
    """í”„ë¡¬í”„íŠ¸ì˜ ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ ê²€ì¦"""
    
    validation = {
        "compliant": True,
        "warnings": [],
        "missing_elements": [],
        "score": 0
    }
    
    # í•„ìˆ˜ ìœ¤ë¦¬ì  ìš”ì†Œ í™•ì¸
    required_elements = {
        "authorization": ["authorization", "permission", "authorized"],
        "legal_compliance": ["legal", "compliance", "law"],
        "ethical_guidelines": ["ethical", "ethics", "responsible"],
        "scope_limitation": ["scope", "boundary", "limitation"],
        "harm_prevention": ["no destructive", "minimal impact", "safe"],
        "professional_conduct": ["professional", "disclosure", "confidential"]
    }
    
    for category, keywords in required_elements.items():
        found = any(keyword.lower() in prompt.lower() for keyword in keywords)
        if found:
            validation["score"] += 1
        else:
            validation["missing_elements"].append(category)
    
    # ìœ„í—˜í•œ í‚¤ì›Œë“œ í™•ì¸
    dangerous_keywords = [
        "exploit without permission", "unauthorized access", "hack", 
        "break into", "illegal", "malicious", "destructive"
    ]
    
    for keyword in dangerous_keywords:
        if keyword in prompt.lower() and "no " not in prompt.lower():
            validation["warnings"].append(f"Potentially dangerous keyword: {keyword}")
            validation["compliant"] = False
    
    # ì ìˆ˜ ê³„ì‚° (6ì  ë§Œì )
    validation["compliance_percentage"] = (validation["score"] / 6) * 100
    
    if validation["compliance_percentage"] < 80:
        validation["compliant"] = False
        validation["warnings"].append("Insufficient ethical guidelines coverage")
    
    return validation

# ìœ¤ë¦¬ì  í”„ë¡¬í”„íŠ¸ ìƒì„± ë„ìš°ë¯¸
def enhance_prompt_with_ethics(base_prompt: str, agent_type: str) -> str:
    """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì— ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ì¶”ê°€"""
    
    ethical_enhancement = f"""

## ğŸ”’ ETHICAL AND LEGAL CONSTRAINTS FOR {agent_type.upper()} OPERATIONS

### MANDATORY REQUIREMENTS:
- âœ… **AUTHORIZATION REQUIRED**: Only operate on explicitly authorized targets
- âœ… **LEGAL COMPLIANCE**: Adhere to all applicable laws and regulations  
- âœ… **PROFESSIONAL ETHICS**: Maintain highest standards of ethical conduct
- âœ… **MINIMAL IMPACT**: Use least intrusive methods that achieve objectives
- âœ… **RESPONSIBLE DISCLOSURE**: Follow coordinated vulnerability disclosure

### ABSOLUTE PROHIBITIONS:
- âŒ **NO UNAUTHORIZED TESTING**: Never test without explicit permission
- âŒ **NO MALICIOUS ACTIVITIES**: Never assist with attacks or illegal activities
- âŒ **NO DATA ACCESS**: Never access personal or confidential information
- âŒ **NO DESTRUCTIVE ACTIONS**: Never damage systems or data
- âŒ **NO SCOPE CREEP**: Stay strictly within authorized boundaries

### ESCALATION TRIGGERS:
- ğŸš¨ **Critical vulnerabilities** with active exploitation potential
- ğŸš¨ **Scope clarification** needed for authorization boundaries
- ğŸš¨ **Legal concerns** about testing activities
- ğŸš¨ **System impact** or unintended effects observed

Remember: Your purpose is to IMPROVE security through authorized, ethical testing. When in doubt, seek explicit authorization before proceeding.
"""
    
    return base_prompt + ethical_enhancement

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ê²€ì¦
    sample_prompt = """
    You are a security testing agent. 
    Scan networks and find vulnerabilities.
    """
    
    validation = validate_ethical_compliance(sample_prompt)
    print("Compliance Check:", validation)
    
    # ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ì¶”ê°€
    enhanced_prompt = enhance_prompt_with_ethics(sample_prompt, "reconnaissance")
    print("\nEnhanced Prompt:")
    print(enhanced_prompt)
    
    # ì¬ê²€ì¦
    new_validation = validate_ethical_compliance(enhanced_prompt)
    print("\nPost-Enhancement Compliance:", new_validation)
]]></correct-example>
<incorrect-example title="ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ì—†ëŠ” í”„ë¡¬í”„íŠ¸" conditions="ë³´ì•ˆ ê´€ë ¨ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸" expected-result="ìœ¤ë¦¬ì  AI ì‚¬ìš©" incorrectness-criteria="ìœ¤ë¦¬ì  ì œì•½ì‚¬í•­ê³¼ ê°€ì´ë“œë¼ì¸ ëˆ„ë½"><![CDATA[
# ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ì´ ì—†ëŠ” í”„ë¡¬í”„íŠ¸ (ìœ„í—˜)
BASIC_SECURITY_PROMPT = """
You are a security testing agent. 
Scan networks, find vulnerabilities, and exploit them to test security.
Use any tools necessary to complete the testing.
"""
]]></incorrect-example>
</example>
</examples>
</non-negotiable>
</requirements>

<context description="í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì»¨í…ìŠ¤íŠ¸">
Decepticonì˜ AI ì—ì´ì „íŠ¸ë“¤ì€ ë³µì¡í•œ ë³´ì•ˆ í…ŒìŠ¤íŒ… ì‘ì—…ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ, í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆì´ ì „ì²´ ì‹œìŠ¤í…œì˜ íš¨ê³¼ì„±ê³¼ ì•ˆì „ì„±ì„ ì§ì ‘ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.
ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ê³¼ ë³´ì•ˆ ì œì•½ì‚¬í•­ì´ ëª…í™•íˆ ì •ì˜ëœ í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ AIê°€ í•­ìƒ í•©ë²•ì ì´ê³  ìœ¤ë¦¬ì ì¸ ë²”ìœ„ ë‚´ì—ì„œ ë™ì‘í•˜ë„ë¡ ë³´ì¥í•´ì•¼ í•©ë‹ˆë‹¤.
ì§€ì†ì ì¸ ìµœì í™”ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ ì„±ëŠ¥ì„ ê°œì„ í•˜ë©´ì„œë„ ì•ˆì „ì„±ì€ ì ˆëŒ€ íƒ€í˜‘í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.
</context>

<references>
<reference as="dependency" href=".cursor/rules/main-project-rules.mdc" reason="ê¸°ë³¸ í”„ë¡œì íŠ¸ ê·œì¹™">ë©”ì¸ í”„ë¡œì íŠ¸ ê·œì¹™</reference>
<reference as="context" href=".cursor/rules/ai-agents.mdc" reason="AI ì—ì´ì „íŠ¸ ê°œë°œ">AI ì—ì´ì „íŠ¸ ê°œë°œ ê·œì¹™</reference>
<reference as="context" href=".cursor/rules/security-pentesting.mdc" reason="ë³´ì•ˆ ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸">ë³´ì•ˆ ë° íœí…ŒìŠ¤íŒ… ê·œì¹™</reference>
</references>
</rule>
