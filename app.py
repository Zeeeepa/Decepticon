import streamlit as st
import time
import os
import asyncio
from datetime import datetime
import json
from pathlib import Path
import re
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

ICON = "assets\logo.png"
ICON_TEXT = "assets\logo_text1.png"

# Streamlit í˜ì´ì§€ ì„¤ì • 
st.set_page_config(
    page_title="Decepticon",
    page_icon=ICON,
    layout="wide",
    # í…Œë§ˆëŠ” í…Œë§ˆ ë§¤ë‹ˆì €ì—ì„œ ê´€ë¦¬
)

# í…Œë§ˆ ê´€ë¦¬ì ì„í¬íŠ¸ 
from frontend.theme_manager import ThemeManager

# í…Œë§ˆ ë§¤ë‹ˆì € ìƒì„± ë° ì„¸ì…˜ ì´ˆê¸°í™”
if "theme_manager" not in st.session_state:
    st.session_state.theme_manager = ThemeManager()

# í…Œë§ˆ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
theme_manager = st.session_state.theme_manager

# í…Œë§ˆ ë° ê¸°ë³¸ CSS ì ìš©
theme_manager.apply_theme()

# ì§ì ‘ ì‹¤í–‰ ëª¨ë“ˆ import
from frontend.direct_executor import DirectExecutor
from frontend.cli_message_processor import CLIMessageProcessor
from frontend.chat_ui import ChatUI
from frontend.terminal_ui import TerminalUI

# ëª¨ë¸ ì„ íƒì„ ìœ„í•œ CLI ëª¨ë“ˆ import
MODEL_SELECTION_AVAILABLE = False
try:
    from src.utils.llm.models import list_available_models, check_ollama_connection
    MODEL_SELECTION_AVAILABLE = True
except ImportError as e:
    print(f"Model selection modules not available: {e}")
    MODEL_SELECTION_AVAILABLE = False

# í„°ë¯¸ë„ UI CSS ì ìš©
terminal_ui = TerminalUI()
terminal_ui.apply_terminal_css()


def get_env_config() -> dict:
    """í™˜ê²½ ì„¤ì • ë¡œë“œ"""
    return {
        "debug_mode": os.getenv("DEBUG_MODE", "false").lower() == "true",
        "theme": os.getenv("THEME", "dark"),
        "docker_container": os.getenv("DOCKER_CONTAINER", "decepticon-kali"),
        "chat_height": int(os.getenv("CHAT_HEIGHT", "700"))
    }


def log_debug(message: str, data=None):
    """ë””ë²„ê·¸ ë¡œê¹…"""
    config = get_env_config()
    if config.get("debug_mode", False):
        print(f"[DEBUG] {message}")
        if data:
            print(f"[DEBUG] Data: {data}")


class DecepticonApp:
    """DecepticonV2 Direct CLI Execution ì• í”Œë¦¬ì¼€ì´ì…˜ - CLIì™€ ì™„ì „íˆ ë™ì¼í•œ ë°©ì‹"""
    
    def __init__(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”"""
        # í™˜ê²½ ì„¤ì • ë¡œë“œ
        self.env_config = get_env_config()
        
        # ë©”ì‹œì§€ ì²˜ë¦¬
        self.message_processor = CLIMessageProcessor()
        self.chat_ui = ChatUI()
        self.terminal_ui = terminal_ui
        
        # í…Œë§ˆ ë§¤ë‹ˆì €
        self.theme_manager = st.session_state.theme_manager
        
        self._initialize_session_state()
        
        # DirectExecutorë¥¼ ì„¸ì…˜ ìƒíƒœì—ì„œ ê´€ë¦¬
        self._setup_executor()
        
        # ë””ë²„ê·¸ ë¡œê·¸
        log_debug("App initialized", {"config": self.env_config})
    
    def _initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        defaults = {
            "executor_ready": False,
            "messages": [],
            "structured_messages": [],
            "terminal_messages": [],
            "current_model": None,
            "workflow_running": False,
            "show_controls": False,
            "initialization_in_progress": False,
            "initialization_error": None,
            # ì—ì´ì „íŠ¸ ìƒíƒœ ì¶”ì  - CLI ë°©ì‹ìœ¼ë¡œ ë‹¨ìˆœí™”
            "active_agent": None,
            "completed_agents": [],
            "current_step": 0,
            # UI ìƒíƒœ
            "keep_initial_ui": True,
            "agent_status_placeholders": {},
            "terminal_placeholder": None,
            # ì´ë²¤íŠ¸ ê¸°ë¡
            "event_history": [],
        }
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
        defaults["debug_mode"] = self.env_config.get("debug_mode", False)
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        for key, default_value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = default_value
    
    def _setup_executor(self):
        """DirectExecutor ì„¤ì • ë° ì„¸ì…˜ ìƒíƒœ ì—°ë™"""
        # DirectExecutorë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if "direct_executor" not in st.session_state:
            st.session_state.direct_executor = DirectExecutor()
            log_debug("DirectExecutor created and stored in session state")
        
        # í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‚¬ìš©í•  executor ì°¸ì¡°
        self.executor = st.session_state.direct_executor
        
        # ìƒíƒœ ë™ê¸°í™”
        if self.executor.is_ready() != st.session_state.executor_ready:
            st.session_state.executor_ready = self.executor.is_ready()
            log_debug(f"Executor ready state synchronized: {st.session_state.executor_ready}")
    
    def reset_session(self):
        """ì„¸ì…˜ ì´ˆê¸°í™”"""
        log_debug("Resetting session")
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        reset_keys = [
            "executor_ready", "messages", "structured_messages", "terminal_messages",
            "workflow_running", "active_agent", "completed_agents", "current_step",
            "agent_status_placeholders", "terminal_placeholder", "event_history",
            "initialization_in_progress", "initialization_error", "current_model"
        ]
        
        for key in reset_keys:
            if key in st.session_state:
                if key in ["agent_status_placeholders"]:
                    st.session_state[key] = {}
                elif key in ["messages", "structured_messages", "terminal_messages", 
                           "completed_agents", "event_history"]:
                    st.session_state[key] = []
                elif key in ["current_step"]:
                    st.session_state[key] = 0
                else:
                    st.session_state[key] = False
        
        # DirectExecutor ì¬ìƒì„±
        st.session_state.direct_executor = DirectExecutor()
        self.executor = st.session_state.direct_executor
        
        log_debug("Session reset completed")
        st.rerun()
    
    def toggle_controls(self):
        """ì»¨íŠ¸ë¡¤ íŒ¨ë„ í† ê¸€"""
        st.session_state.show_controls = not st.session_state.show_controls
        log_debug(f"Controls toggled: {st.session_state.show_controls}")
    
    def set_debug_mode(self, mode):
        """ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •"""
        st.session_state.debug_mode = mode
        log_debug(f"Debug mode set to: {mode}")
    
    def display_model_selection(self):
        """LLM ëª¨ë¸ ì„ íƒ í™”ë©´ - ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬"""
        if not MODEL_SELECTION_AVAILABLE:
            st.error("Model selection not available. Please check CLI dependencies.")
            st.info(
                "To enable model selection, ensure the following modules are available:\n"
                "- src.utils.llm.models\n"
                "- All CLI dependencies\n\n"
                "You can still use the application with default settings."
            )
            return None
        
        st.markdown("### ğŸ¤– Model Selection")
        st.markdown("Choose your AI model for red team operations")
        
        try:
            with st.spinner("Loading available models..."):
                models = list_available_models()
                ollama_info = check_ollama_connection()
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ í•„í„°ë§
            available_models = [m for m in models if m.get("api_key_available", False)]
            
            if not available_models:
                st.error("""
                **No models available**
                
                Setup required:
                - Set API keys in .env file (OPENAI_API_KEY, ANTHROPIC_API_KEY, etc.)
                - Or install Ollama from https://ollama.ai/
                """)
                return None
            
            # ëª¨ë¸ ì„ íƒ UI
            model_options = []
            for model in available_models:
                display_text = f"{model['display_name']} ({model['provider']})"
                model_options.append(display_text)
            
            selected_index = st.selectbox(
                "Select Model:",
                range(len(model_options)),
                format_func=lambda x: model_options[x],
                key="model_selector"
            )
            
            selected_model = available_models[selected_index]
            
            # Ollama ìƒíƒœ í‘œì‹œ
            if ollama_info["connected"]:
                st.success(f"ğŸ¦™ Ollama: Running ({ollama_info['count']} models available)")
            
            # ëª¨ë¸ ì •ë³´ í‘œì‹œ
            with st.expander("Model Details", expanded=False):
                st.json({
                    "Display Name": selected_model['display_name'],
                    "Provider": selected_model['provider'],
                    "Model Name": selected_model['model_name']
                })
            
            return selected_model
            
        except Exception as e:
            st.error(f"Error loading models: {str(e)}")
            log_debug(f"Model selection error: {str(e)}")
            return None
    
    async def initialize_executor_async(self, model_info=None):
        """ë¹„ë™ê¸° ì‹¤í–‰ê¸° ì´ˆê¸°í™”"""
        try:
            log_debug(f"Starting async executor initialization with model: {model_info}")
            
            if model_info:
                await self.executor.initialize_swarm(model_info)
                st.session_state.current_model = model_info
                log_debug(f"Executor initialized with model: {model_info['display_name']}")
            else:
                await self.executor.initialize_swarm()
                log_debug("Executor initialized with default settings")
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.executor_ready = True
            st.session_state.initialization_in_progress = False
            st.session_state.initialization_error = None
            
            log_debug("Executor initialization completed successfully")
            return True
            
        except Exception as e:
            error_msg = f"Failed to initialize AI agents: {str(e)}"
            log_debug(f"Executor initialization failed: {error_msg}")
            
            # ì—ëŸ¬ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.executor_ready = False
            st.session_state.initialization_in_progress = False
            st.session_state.initialization_error = error_msg
            
            return False
    
    def initialize_executor(self, model_info=None):
        """ì‹¤í–‰ê¸° ì´ˆê¸°í™” (ë™ê¸° ë˜í¼)"""
        if st.session_state.initialization_in_progress:
            st.warning("Initialization already in progress...")
            return
        
        try:
            # ì´ˆê¸°í™” ì‹œì‘
            st.session_state.initialization_in_progress = True
            st.session_state.initialization_error = None
            
            with st.status("Initializing AI agents...", expanded=True) as status:
                if model_info:
                    status.update(label=f"Setting up {model_info['display_name']}...")
                else:
                    status.update(label="Initializing with current settings...")
                
                # ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹¤í–‰
                result = asyncio.run(self.initialize_executor_async(model_info))
                
                if result:
                    status.update(label="âœ… AI agents ready!", state="complete")
                    log_debug("Executor initialization completed")
                    time.sleep(1)
                    st.rerun()
                else:
                    status.update(label="âŒ Initialization failed!", state="error")
                    if st.session_state.initialization_error:
                        st.error(st.session_state.initialization_error)
                    
        except Exception as e:
            error_msg = f"Initialization error: {str(e)}"
            st.session_state.initialization_error = error_msg
            st.session_state.initialization_in_progress = False
            st.error(error_msg)
            log_debug(f"Initialization exception: {error_msg}")
    
    def _extract_agent_name_from_namespace(self, namespace):
        """namespaceì—ì„œ ì—ì´ì „íŠ¸ ì´ë¦„ ì¶”ì¶œ - CLIì™€ ë™ì¼í•œ ë¡œì§"""
        if not namespace or len(namespace) == 0:
            return None
        
        namespace_str = namespace[0]
        if ':' in namespace_str:
            return namespace_str.split(':')[0]
        
        return namespace_str
    
    def _update_agent_status_from_events(self, agents_container):
        """ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ì—ì„œ ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ - CLIì™€ ë™ì¼í•œ ë°©ì‹"""
        # ìµœê·¼ ì´ë²¤íŠ¸ì—ì„œ í™œì„± ì—ì´ì „íŠ¸ ì°¾ê¸°
        active_agent = None
        for event in reversed(st.session_state.event_history):
            if event.get("type") == "message" and event.get("message_type") == "ai":
                agent_name = event.get("agent_name")
                if agent_name and agent_name != "Unknown":
                    active_agent = agent_name.lower()
                    break
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        if active_agent and active_agent != st.session_state.active_agent:
            # ì´ì „ í™œì„± ì—ì´ì „íŠ¸ë¥¼ ì™„ë£Œ ëª©ë¡ì— ì¶”ê°€
            if st.session_state.active_agent and st.session_state.active_agent not in st.session_state.completed_agents:
                st.session_state.completed_agents.append(st.session_state.active_agent)
            
            st.session_state.active_agent = active_agent
            log_debug(f"Active agent updated to: {active_agent}")
        
        # UI ìƒíƒœ ì—…ë°ì´íŠ¸
        if st.session_state.get("keep_initial_ui", True) and (
            st.session_state.active_agent or st.session_state.completed_agents
        ):
            st.session_state.keep_initial_ui = False
        
        # ìƒíƒœ í‘œì‹œ ì—…ë°ì´íŠ¸
        self.chat_ui.display_agent_status(
            agents_container,
            st.session_state.active_agent,
            None,  # active_stage ì œê±°
            st.session_state.completed_agents
        )
    
    async def execute_workflow(self, user_input: str, chat_area, agents_container):
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ - CLIì™€ ì™„ì „íˆ ë™ì¼í•œ ë°©ì‹"""
        # ìƒíƒœ ê²€ì¦
        if not st.session_state.executor_ready:
            st.error("AI agents not ready. Please initialize first.")
            log_debug("Workflow execution rejected: executor not ready")
            return
        
        if not self.executor.is_ready():
            st.error("Executor state mismatch. Please reset and try again.")
            log_debug("Workflow execution rejected: executor state mismatch")
            return
        
        if st.session_state.workflow_running:
            st.warning("Another workflow is already running. Please wait.")
            return
        
        log_debug(f"Executing workflow: {user_input[:50]}...")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_message = self.message_processor._create_user_message(user_input)
        st.session_state.structured_messages.append(user_message)
        
        # UIì— ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with chat_area:
            self.chat_ui.display_user_message(user_input)
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìƒíƒœ ì„¤ì •
        st.session_state.workflow_running = True
        
        try:
            with st.status("ğŸ¤– AI agents working...", expanded=True) as status:
                event_count = 0
                agent_activity = {}  # ì—ì´ì „íŠ¸ í™œë™ ì¶”ì 
                
                # CLI ì›Œí¬í”Œë¡œìš° ì§ì ‘ ì‹¤í–‰ - CLIì™€ ì™„ì „íˆ ë™ì¼
                async for event in self.executor.execute_workflow(user_input):
                    event_count += 1
                    st.session_state.event_history.append(event)
                    
                    try:
                        # ë””ë²„ê·¸ ëª¨ë“œì—ì„œ ì´ë²¤íŠ¸ í‘œì‹œ
                        if st.session_state.debug_mode:
                            with chat_area:
                                st.json(event)
                        
                        event_type = event.get("type", "")
                        
                        if event_type == "message":
                            # CLI ë©”ì‹œì§€ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ - CLIì™€ ì™„ì „íˆ ë™ì¼
                            frontend_message = self.message_processor.process_cli_event(event)
                            
                            # ì¤‘ë³µ ê²€ì‚¬ - CLIì™€ ë™ì¼í•œ ë¡œì§
                            if not self.message_processor.is_duplicate_message(
                                frontend_message, st.session_state.structured_messages
                            ):
                                st.session_state.structured_messages.append(frontend_message)
                                
                                # ì—ì´ì „íŠ¸ í™œë™ ì¶”ì 
                                agent_name = event.get("agent_name", "Unknown")
                                if agent_name not in agent_activity:
                                    agent_activity[agent_name] = 0
                                agent_activity[agent_name] += 1
                                
                                # ìƒíƒœ ì—…ë°ì´íŠ¸
                                status.update(
                                    label=f"ğŸ¤– {agent_name} working... (Step {event_count})",
                                    state="running"
                                )
                                
                                # ë©”ì‹œì§€ í‘œì‹œ - CLIì™€ ë™ì¼í•œ ë°©ì‹
                                with chat_area:
                                    self._display_message(frontend_message)
                                
                                # í„°ë¯¸ë„ ë©”ì‹œì§€ ì²˜ë¦¬ - CLIì™€ ë™ì¼í•œ ë°©ì‹
                                if frontend_message.get("type") == "tool":
                                    st.session_state.terminal_messages.append(frontend_message)
                                    if st.session_state.terminal_placeholder:
                                        self.terminal_ui.process_structured_messages([frontend_message])
                        
                        elif event_type == "workflow_complete":
                            status.update(label="âœ… Workflow completed!", state="complete")
                            log_debug(f"Workflow completed. Processed {event_count} events")
                        
                        elif event_type == "error":
                            error_msg = event.get("error", "Unknown error")
                            status.update(label=f"âŒ Error: {error_msg}", state="error")
                            st.error(f"Workflow error: {error_msg}")
                            log_debug(f"Workflow error: {error_msg}")
                        
                        # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ - CLIì™€ ë™ì¼í•œ ë°©ì‹
                        self._update_agent_status_from_events(agents_container)
                        
                    except Exception as e:
                        log_debug(f"Event processing error: {str(e)}")
                        if st.session_state.debug_mode:
                            st.error(f"Event processing error: {str(e)}")
                
                # ì™„ë£Œ í›„ ìš”ì•½ í‘œì‹œ
                if agent_activity:
                    summary_text = f"Completed! Events: {event_count}, Active agents: {', '.join(agent_activity.keys())}"
                    status.update(label=f"âœ… {summary_text}", state="complete")
        
        except Exception as e:
            st.error(f"Workflow execution error: {str(e)}")
            log_debug(f"Workflow execution error: {str(e)}")
        
        finally:
            st.session_state.workflow_running = False
    
    def _display_message(self, message):
        """ë©”ì‹œì§€ í‘œì‹œ - CLIì™€ ë™ì¼"""
        message_type = message.get("type", "")
        
        if message_type == "ai":
            self.chat_ui.display_agent_message(message, streaming=True)
        elif message_type == "tool":
            self.chat_ui.display_tool_message(message)
    
    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        # í…Œë§ˆ ìƒíƒœ í™•ì¸
        current_theme = self.theme_manager.get_current_theme()
        log_debug(f"Running Decepticon with theme: {current_theme}")
        
        st.logo(
            ICON_TEXT,
            icon_image=ICON,
            size="large",
            link="https://purplelab.framer.ai"
        )

        # ë©”ì¸ ì œëª©
        st.title(":red[Decepticon]")
        
        # í™˜ê²½ ì •ë³´ í‘œì‹œ (ë””ë²„ê·¸ ëª¨ë“œ)
        if st.session_state.debug_mode:
            with st.expander("ğŸ”§ Environment Info", expanded=False):
                st.json(self.env_config)
                
                # Executor ìƒíƒœ ì •ë³´
                if hasattr(self, 'executor'):
                    st.subheader("Executor State")
                    st.json(self.executor.get_state_dict())
        
        # ì‚¬ì´ë“œë°” ì„¤ì •
        sidebar = st.sidebar
        
        # 1. íƒ€ì´í‹€
        title_container = sidebar.container()
        title_container.title("Agent Status")
        
        # 2. ì—ì´ì „íŠ¸ ëª©ë¡
        agents_container = sidebar.container()
        self.chat_ui.display_agent_status(
            agents_container,
            st.session_state.active_agent,
            None,  # active_stage ì œê±°
            st.session_state.completed_agents
        )
        
        # 3. êµ¬ë¶„ì„ 
        divider_container = sidebar.container()
        divider_container.divider()
        
        # 4. ì»¨íŠ¸ë¡¤ íŒ¨ë„
        control_container = sidebar.container()
        cols = control_container.columns(2)
        
        # ì»¨íŠ¸ë¡¤ íŒ¨ë„ ë²„íŠ¼
        if cols[0].button("âš™ï¸ Control", use_container_width=True):
            self.toggle_controls()
        
        # í…Œë§ˆ í† ê¸€
        self.theme_manager.create_theme_toggle(cols[1])
        
        # 5. ì»¨íŠ¸ë¡¤ íŒ¨ë„ ë‚´ìš©
        control_panel_container = sidebar.container()
        if st.session_state.show_controls:
            with control_panel_container.expander("Control", expanded=True):
                # ì‹¤í–‰ê¸° ìƒíƒœ
                if st.session_state.executor_ready and self.executor.is_ready():
                    st.success("âœ… AI Agents Ready")
                    if st.session_state.current_model:
                        st.info(f"Model: {st.session_state.current_model.get('display_name', 'Unknown')}")
                    if st.button("Reset Session"):
                        self.reset_session()
                elif st.session_state.initialization_in_progress:
                    st.info("ğŸ”„ Initializing...")
                elif st.session_state.initialization_error:
                    st.error(f"âŒ Init Error: {st.session_state.initialization_error}")
                else:
                    st.warning("âš ï¸ AI Agents Not Ready")
                
                # ë””ë²„ê·¸ ëª¨ë“œ
                debug_mode = st.checkbox("Debug Mode", value=st.session_state.debug_mode)
                self.set_debug_mode(debug_mode)
                
                # ì›Œí¬í”Œë¡œìš° ìƒíƒœ
                if st.session_state.workflow_running:
                    st.info("ğŸ”„ Workflow Running...")
                
                # í†µê³„
                st.subheader("Statistics")
                st.text(f"Messages: {len(st.session_state.structured_messages)}")
                st.text(f"Events: {len(st.session_state.event_history)}")
                st.text(f"Step: {st.session_state.current_step}")
        
        # ë ˆì´ì•„ì›ƒ: ë‘ ê°œì˜ ì—´ë¡œ ë¶„í•  (ì±„íŒ…ê³¼ í„°ë¯¸ë„)
        chat_column, terminal_column = st.columns([2, 1])
        
        # í„°ë¯¸ë„ ì˜ì—­ ì´ˆê¸°í™”
        with terminal_column:
            st.session_state.terminal_placeholder = self.terminal_ui.create_terminal(terminal_column)
            
            # ì €ì¥ëœ í„°ë¯¸ë„ ë©”ì‹œì§€ ë³µì›
            if st.session_state.terminal_messages:
                self.terminal_ui.process_structured_messages(st.session_state.terminal_messages)
        
        # ì±„íŒ… ì˜ì—­ ì²˜ë¦¬
        with chat_column:
            # ì‹¤í–‰ê¸° ì´ˆê¸°í™” í™•ì¸
            if not st.session_state.executor_ready:
                if st.session_state.initialization_in_progress:
                    st.info("ğŸ”„ Initializing AI agents... Please wait.")
                    return
                
                if st.session_state.initialization_error:
                    st.error(f"âŒ Initialization failed: {st.session_state.initialization_error}")
                    if st.button("ğŸ”„ Retry Initialization"):
                        st.session_state.initialization_error = None
                        st.rerun()
                
                st.info("ğŸ¤– Initialize AI agents to start red team operations")
                
                # ëª¨ë¸ ì„ íƒ
                selected_model = self.display_model_selection()
                
                if selected_model and st.button("ğŸš€ Initialize AI Agents", type="primary"):
                    self.initialize_executor(selected_model)
                return
            
            # ì±„íŒ… ì˜ì—­
            chat_height = self.env_config.get("chat_height", 700)
            chat_container = st.container(height=chat_height, border=False)
            
            with chat_container:
                # ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
                messages_area = st.container()
                
                # ì…ë ¥ì°½ ì˜ì—­
                input_container = st.container()
                
                # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
                with messages_area:
                    if st.session_state.debug_mode:
                        st.warning("Debug Mode: Event data will be displayed during processing")
                    
                    # ì €ì¥ëœ êµ¬ì¡°í™” ë©”ì‹œì§€ í‘œì‹œ
                    if not st.session_state.workflow_running:
                        self.chat_ui.display_messages(st.session_state.structured_messages, messages_area)
                
                # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
                with input_container:
                    user_input = st.chat_input("Type your red team request here...")
                    
                    if user_input and not st.session_state.workflow_running:
                        asyncio.run(self.execute_workflow(user_input, messages_area, agents_container))


if __name__ == "__main__":
    app = DecepticonApp()
    app.run()
